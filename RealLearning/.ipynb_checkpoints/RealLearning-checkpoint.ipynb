{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TensorFlow to Predict Drug Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. DNNLinearCombinedClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import constants\n",
    "\n",
    "from tensorflow.contrib.learn.python.learn.datasets import base\n",
    "\n",
    "# Less Verbose Output\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "DATA_DIR = \"Dataset/\"\n",
    "DRUG_TRAINING = DATA_DIR + \"re_drug_consumption_data.csv\"\n",
    "DRUG_TEST = DATA_DIR + \"test_drug_consumption_data.csv\"\n",
    "DRUG_PREDICT = DATA_DIR + \"predict_drug_consumption_data.csv\"\n",
    "\n",
    "PREDICT_OUTPUT = DATA_DIR + \"predictions.csv\"\n",
    "\n",
    "# Bucketization for possible nonlinear relationship\n",
    "age = tf.feature_column.numeric_column(\"age\")\n",
    "age_buckets = tf.feature_column.bucketized_column(\n",
    "    age, boundaries=constants.AGE_BOUNDARIES)\n",
    "gender = tf.feature_column.numeric_column(\"gender\")\n",
    "gender_buckets = tf.feature_column.bucketized_column(\n",
    "    gender, boundaries=constants.GENDER_BOUNDARIES)\n",
    "country = tf.feature_column.numeric_column(\"country\")\n",
    "country_buckets = tf.feature_column.bucketized_column(\n",
    "    country, boundaries=constants.COUNTRY_BOUNDARIES)\n",
    "ethnicity = tf.feature_column.numeric_column(\"ethnicity\")\n",
    "ethnicity_buckets = tf.feature_column.bucketized_column(\n",
    "    ethnicity, boundaries=constants.ETHNICITY_BOUNDARIES)\n",
    "education = tf.feature_column.numeric_column(\"education\")\n",
    "education_buckets = tf.feature_column.bucketized_column(\n",
    "    education, boundaries=constants.EDUCATION_BOUNDARIES)\n",
    "\n",
    "# Could bucketize but guessing these are close to linear\n",
    "nscore = tf.feature_column.numeric_column(\"nscore\")\n",
    "escore = tf.feature_column.numeric_column(\"escore\")\n",
    "oscore = tf.feature_column.numeric_column(\"oscore\")\n",
    "ascore = tf.feature_column.numeric_column(\"ascore\")\n",
    "cscore = tf.feature_column.numeric_column(\"cscore\")\n",
    "impulsive = tf.feature_column.numeric_column(\"impulsive\")\n",
    "ss = tf.feature_column.numeric_column(\"ss\")\n",
    "\n",
    "nscore_ascore = tf.feature_column.crossed_column(\n",
    "    [\"nscore\", \"ascore\"], hash_bucket_size=500)\n",
    "nscore_cscore = tf.feature_column.crossed_column(\n",
    "    [\"nscore\", \"cscore\"], hash_bucket_size=500)\n",
    "ascore_cscore = tf.feature_column.crossed_column(\n",
    "    [\"ascore\", \"cscore\"], hash_bucket_size=500)\n",
    "nscore_ascore_cscore = tf.feature_column.crossed_column(\n",
    "    [\"nscore\", \"ascore\", \"cscore\"], hash_bucket_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(data_file, target, num_epochs, batch_size=30, shuffle=False, num_threads=1):\n",
    "    dataset = pd.read_csv(\n",
    "        tf.gfile.Open(data_file),\n",
    "        header=0,\n",
    "        usecols=constants.FEATURE_COLUMNS + [target],\n",
    "        skipinitialspace=True,\n",
    "        engine=\"python\")\n",
    "    # Drop NaN entries\n",
    "    dataset.dropna(how=\"any\", axis=0)\n",
    "\n",
    "    # Init empty dataframe, add column for each of targets\n",
    "    labels = pd.DataFrame(columns=[target])\n",
    "    \n",
    "    # This assigns a different number to each usage category\n",
    "    # labels[constants.TARGET] = dataset[constants.TARGET].apply(lambda x: constants.MAPPED_CODES[x]).astype(int)\n",
    "\n",
    "    # This classifies usage as binary (USER/NON-USER) to make prediction easier\n",
    "    labels[target] = dataset[target].apply(lambda x: x in constants.USER).astype(int)\n",
    "\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "        x=dataset,\n",
    "        y=labels,\n",
    "        batch_size=batch_size,\n",
    "        num_epochs=num_epochs,\n",
    "        shuffle=shuffle,\n",
    "        num_threads=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_columns = [\n",
    "    age_buckets, gender_buckets, country_buckets, ethnicity_buckets,\n",
    "    education_buckets,\n",
    "    # For alcohol, purposefully removing personality features to reduce noise\n",
    "    # nscore, escore,\n",
    "    # oscore, ascore, cscore, impulsive,\n",
    "    # ss\n",
    "]\n",
    "\n",
    "crossed_columns = [\n",
    "    # See comment above\n",
    "    # nscore_ascore, nscore_cscore, ascore_cscore,\n",
    "    # nscore_ascore_cscore\n",
    "]\n",
    "\n",
    "feature_columns = base_columns + crossed_columns\n",
    "\n",
    "classifier = tf.estimator.DNNLinearCombinedClassifier(\n",
    "    model_dir=constants.MODEL_DIR,\n",
    "    n_classes=2,\n",
    "    linear_feature_columns=crossed_columns,\n",
    "    dnn_feature_columns=base_columns,\n",
    "    dnn_hidden_units=[36],\n",
    "    dnn_optimizer=tf.train.ProximalAdagradOptimizer(\n",
    "        learning_rate=0.1,\n",
    "        l1_regularization_strength=0.002,\n",
    "        l2_regularization_strength=0.01))\n",
    "\n",
    "classifier.train(input_fn=input_fn(DRUG_TRAINING, target=\"alcohol\", num_epochs=None, shuffle=True),\n",
    "    steps=60000)\n",
    "\n",
    "results = classifier.evaluate(input_fn=input_fn(DRUG_TEST, target=\"alcohol\", num_epochs=1,\n",
    "    shuffle=False), steps=None)\n",
    "\n",
    "print(\"Accuracy: %s\" % results['accuracy'])\n",
    "\n",
    "def predict(classifier, target):\n",
    "    predictions = classifier.predict(input_fn=input_fn(DRUG_PREDICT, target=target, num_epochs=1,\n",
    "        shuffle=False))\n",
    "    predict_writer = open(PREDICT_OUTPUT, \"w\")\n",
    "    predict_writer.write(\"Fake header\\n\")\n",
    "    for prediction in list(predictions):\n",
    "        curr_line = \"\"\n",
    "        for class_id in prediction['class_ids']:\n",
    "            curr_line += (str(class_id) + ',')\n",
    "        predict_writer.write(curr_line[:-1] + '\\n')\n",
    "\n",
    "    predict_writer.close()\n",
    "\n",
    "predict(classifier, \"alcohol\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, it's nowhere near the accuracy I saw with MNIST, but I think it's respectable.  I also separated out 200 cases on which I used `classifier.predict()` instead of `evaluate()`.  The cell below calculates accuracy, sensitivity and specifity on this sample of 200 using a separate [python script](https://github.com/emdoyle/tensorflow_stuff/tree/master/RealLearning/compare_results.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compare_results import compare_results\n",
    "compare_results([\"alcohol\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's worth noting (if only for a chance at interpretation) that the specifity in this sample is far below the sensitivity. This means that it was much more difficult for the model to predict that someone _didn't_ drink alcohol than if they did.  I suspect that this is because the model assumes a very positive bias, since guessing positively is usually correct.  Later it may be possible to correct this, but for now I will move on to other usages, since the optimal hyperparameters are likely to be different for different targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_columns = [\n",
    "    age_buckets, gender_buckets, country_buckets, ethnicity_buckets,\n",
    "    education_buckets,\n",
    "]\n",
    "\n",
    "# Although the individual personality traits aren't crossed columns,\n",
    "# I think they will do better as input to the linear part of the model\n",
    "crossed_columns = [\n",
    "    nscore_ascore_cscore, nscore, escore, oscore, ascore, cscore, impulsive,\n",
    "    ss\n",
    "]\n",
    "\n",
    "feature_columns = base_columns + crossed_columns\n",
    "\n",
    "classifier = tf.estimator.DNNLinearCombinedClassifier(\n",
    "    model_dir=constants.MODEL_DIR + \"_cannabis\",\n",
    "    n_classes=2,\n",
    "    linear_feature_columns=crossed_columns,\n",
    "    dnn_feature_columns=base_columns,\n",
    "    dnn_hidden_units=[144, 72, 36, 18],\n",
    "    dnn_optimizer=tf.train.ProximalAdagradOptimizer(\n",
    "        learning_rate=0.1,\n",
    "        l1_regularization_strength=0.002,\n",
    "        l2_regularization_strength=0.005))\n",
    "\n",
    "classifier.train(input_fn=input_fn(DRUG_TRAINING, target=\"cannabis\", num_epochs=None, shuffle=True),\n",
    "    steps=60000)\n",
    "\n",
    "results = classifier.evaluate(input_fn=input_fn(DRUG_TEST, target=\"cannabis\", num_epochs=1,\n",
    "    shuffle=False), steps=None)\n",
    "\n",
    "print(\"Accuracy: %s\" % results['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(classifier, \"cannabis\")\n",
    "compare_results([\"cannabis\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm very surprised at the disparity between the `evaluate()` reported accuracy and the `predict()` reported accuracy.  It is possible that since the 200 is a small portion (~10%) of the total samples that it contains a significant number of outliers in terms of cannabis usage, or perhaps the model is overfitted to the data it saw.  I believe if the problem is overfitting that the solution is higher regularization strength, but if it is poor data then I will need to tweak my `constants` file to up the portion of the data used for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = tf.estimator.DNNLinearCombinedClassifier(\n",
    "    model_dir=constants.MODEL_DIR + \"_cannabis\",\n",
    "    n_classes=2,\n",
    "    linear_feature_columns=crossed_columns,\n",
    "    dnn_feature_columns=base_columns,\n",
    "    dnn_hidden_units=[72, 36, 18],\n",
    "    dnn_optimizer=tf.train.ProximalAdagradOptimizer(\n",
    "        learning_rate=0.1,\n",
    "        l1_regularization_strength=0.05,\n",
    "        l2_regularization_strength=0.15))\n",
    "\n",
    "classifier.train(input_fn=input_fn(DRUG_TRAINING, target=\"cannabis\", num_epochs=None, shuffle=True),\n",
    "    steps=60000)\n",
    "\n",
    "results = classifier.evaluate(input_fn=input_fn(DRUG_TEST, target=\"cannabis\", num_epochs=1,\n",
    "    shuffle=False), steps=None)\n",
    "\n",
    "print(\"Accuracy: %s\" % results['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(classifier, \"cannabis\")\n",
    "compare_results([\"cannabis\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regularization _does_ seem to have helped with the prediction metrics without much of an impact on evaluation accuracy.  Also I did remove the first hidden layer since I felt four hidden layers might be too much for a relatively simple binary classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Homemade Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the `DNNLinearCombinedClassifier` certainly performed well, to really have full control over the training model I will need to build an Estimator using `tf.estimator`.  Since I won't be using a pre-built classifier, I will need to create my own model function, which involves defining the layers of the network, loss, the optimizer, the learning rate, and whatever other parameters I choose to modify.  Below is the skeleton of a model function, taken from [here](https://www.tensorflow.org/extend/estimators)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_fn(features, labels, mode, params):\n",
    "    # Logic to do the following:\n",
    "    # 1. Configure the model via TensorFlow operations\n",
    "    # 2. Define the loss function for training/evaluation\n",
    "    # 3. Define the training operation/optimizer\n",
    "    # 4. Generate predictions\n",
    "    # 5. Return predictions/loss/train_op/eval_metric_ops in EstimatorSpec object\n",
    "#   return EstimatorSpec(mode, predictions, loss, train_op, eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(data_file, target, num_epochs, batch_size=30, shuffle=False, num_threads=1):\n",
    "    dataset = pd.read_csv(\n",
    "        tf.gfile.Open(data_file),\n",
    "        header=0,\n",
    "        usecols=constants.FEATURE_COLUMNS + [target],\n",
    "        skipinitialspace=True,\n",
    "        engine=\"python\")\n",
    "    # Drop NaN entries\n",
    "    dataset.dropna(how=\"any\", axis=0)\n",
    "\n",
    "    # Init empty dataframe, add column for each of targets\n",
    "    labels = pd.DataFrame(columns=[target])\n",
    "    \n",
    "    # This assigns a different number to each usage category\n",
    "    # labels[constants.TARGET] = dataset[constants.TARGET].apply(lambda x: constants.MAPPED_CODES[x]).astype(int)\n",
    "\n",
    "    # This classifies usage as binary (USER/NON-USER) to make prediction easier\n",
    "    labels[target] = dataset[target].apply(lambda x: x in constants.USER).astype(int)\n",
    "    dataset.pop(target)\n",
    "    \n",
    "    return tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\": np.array(dataset)},\n",
    "        y=np.array(labels[target]),\n",
    "        batch_size=batch_size,\n",
    "        num_epochs=num_epochs,\n",
    "        shuffle=shuffle,\n",
    "        num_threads=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    \n",
    "    # 1. Configure the model via TensorFlow operations\n",
    "    input_layer = tf.cast(features[\"x\"], tf.float32)\n",
    "    \n",
    "    layer_sizes = params[\"hidden_layers\"]\n",
    "    current_tensor = input_layer\n",
    "    for nodes in layer_sizes:\n",
    "        current_tensor = tf.layers.dense(current_tensor, nodes, activation=tf.nn.sigmoid)\n",
    "        \n",
    "    output_layer = tf.layers.dense(current_tensor, 1)\n",
    "\n",
    "    # 4. Generate predictions\n",
    "    predictions = tf.reshape(output_layer, [-1])\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            predictions={\"usage\": predictions})\n",
    "    \n",
    "    # 2. Define the loss function for training/evaluation\n",
    "\n",
    "    loss = tf.losses.mean_squared_error(labels, predictions)\n",
    "\n",
    "    thresh_predictions = tf.where(tf.less(predictions, tf.constant(0.5, tf.float32)),\n",
    "                             tf.zeros(tf.shape(predictions)), tf.ones(tf.shape(predictions)))\n",
    "    eval_metric_ops = {\n",
    "        \"rmse\": tf.metrics.root_mean_squared_error(tf.cast(labels,tf.float64), tf.cast(predictions,tf.float64)),\n",
    "        \"accuracy\": tf.metrics.accuracy(\n",
    "            tf.cast(labels, tf.float64), tf.cast(thresh_predictions, tf.float64))\n",
    "    }\n",
    "    \n",
    "    # 3. Define the training operation/optimizer\n",
    "    decay_steps = 50000\n",
    "    learning_rate = tf.train.polynomial_decay(params[\"start_learn\"], tf.train.get_global_step(),\n",
    "                                          decay_steps, params[\"end_learn\"],\n",
    "                                          power=0.5)\n",
    "    optimizer=tf.train.GradientDescentOptimizer(\n",
    "        learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "    \n",
    "    # 5. Return predictions/loss/train_op/eval_metric_ops in EstimatorSpec object\n",
    "    return tf.estimator.EstimatorSpec(mode, predictions, loss, train_op, eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_columns = [\n",
    "    age_buckets, gender_buckets, country_buckets, ethnicity_buckets,\n",
    "    education_buckets,\n",
    "]\n",
    "\n",
    "# Although the individual personality traits aren't crossed columns,\n",
    "# I think they will do better as input to the linear part of the model\n",
    "# tf.feature_column.embedding_column(nscore_ascore_cscore, 1), \n",
    "crossed_columns = [\n",
    "    nscore, escore, oscore, ascore, cscore, impulsive,\n",
    "    ss\n",
    "]\n",
    "\n",
    "feature_columns = base_columns + crossed_columns\n",
    "\n",
    "model_params = {\n",
    "    \"feature_columns\": feature_columns,\n",
    "    \"hidden_layers\": [30, 10],\n",
    "    \"start_learn\": 0.1,\n",
    "    \"end_learn\": 0.01\n",
    "}\n",
    "\n",
    "nn = tf.estimator.Estimator(model_fn, params=model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.train(input_fn=input_fn(DRUG_TRAINING, target=\"cannabis\", batch_size=1, num_epochs=None, shuffle=True),\n",
    "    steps=60000)\n",
    "\n",
    "results = nn.evaluate(input_fn=input_fn(DRUG_TEST, target=\"cannabis\", batch_size=1, num_epochs=1,\n",
    "    shuffle=False), steps=None)\n",
    "\n",
    "print(results)\n",
    "print(\"Accuracy: %s\" % results['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nn.predict(input_fn=input_fn(DRUG_PREDICT, target=\"cannabis\", num_epochs=1,\n",
    "    shuffle=False))\n",
    "print(list(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
