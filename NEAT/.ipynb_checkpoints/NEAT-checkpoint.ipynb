{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using NEAT to Evolve Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MultiNEAT as NEAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was sort of a pain to install, but the good news is it's all set up now and I have openCV 3.3.0 installed as well.  Basically [this](http://multineat.com/docs.html) is the extent of the documentation since I don't believe this library has been widely used.  It's also not fully compatible with the current `boost` version (1.65) because one of the header files was removed (`numeric.hpp`) so I used `cython` to build it instead (although the new files related to Traits require me to have `boost` installed anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is NEAT?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEAT stands for [\"NeuroEvolution of Augmenting Topologies\"](https://en.wikipedia.org/wiki/Neuroevolution_of_augmenting_topologies) and is a genetic algorithm for evolving neural networks.  It is based on the idea that mutation, speciation, and natural selection can begin with very simple structures and eventually evolve complex topologies that maximize a given fitness function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are really two distinct ways to use NEAT:\n",
    "\n",
    "    1. Decide on the topology of the neural network ahead of time and simply evolve connection\n",
    "    weights and biases.\n",
    "\n",
    "![caption](files/PreDetermTopo.png)\n",
    "\n",
    "    2. Start with a very simple network consisting of only input and output layers and evolve new nodes\n",
    "    and connections along with connection weights and biases.\n",
    "\n",
    "![caption](files/EvolvedTopo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolving a Neural Network That Outputs [1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started with NEAT, I am going to go through a toy example.  It will involve initializing a population of simple genomes, constructing neural network phenotypes based on these genomes, defining an evaluation function to determine the fitness of a given phenotype, and defining an epoch cycle to iterate through new generations. (NOTE: This code will primarily come from the [documentation page](http://multineat.com/docs.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = NEAT.Parameters()\n",
    "\n",
    "params.PopulationSize = 100\n",
    "\n",
    "# The Genome constructor (in C++) is copied below\n",
    "# Genome::Genome(unsigned int a_ID,\n",
    "#                    unsigned int a_NumInputs,\n",
    "#                    unsigned int a_NumHidden, // ignored for seed type == 0, specifies number of hidden units if seed type == 1\n",
    "#                    unsigned int a_NumOutputs,\n",
    "#                    bool a_FS_NEAT, ActivationFunction a_OutputActType,\n",
    "#                    ActivationFunction a_HiddenActType,\n",
    "#                    unsigned int a_SeedType,\n",
    "#                    const Parameters &a_Parameters)\n",
    "\n",
    "genome = NEAT.Genome(0, 3, 0, 2, False,\n",
    "                     NEAT.ActivationFunction.UNSIGNED_SIGMOID,\n",
    "                     NEAT.ActivationFunction.UNSIGNED_SIGMOID, 0, params)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The author of the documentation (likely also the author of the library) tells us to: \"Always add one extra input. The last input is always used as bias and also when you activate the network always set the last input to 1.0 (or any other constant non-zero value).\" Knowing this, the network we defined just now has 2 'real' inputs and 2 outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Population constructor (again in C++) is copied below\n",
    "# Population::Population(const Genome& a_Seed, const Parameters& a_Parameters,\n",
    "#     bool a_RandomizeWeights, double a_RandomizationRange, int a_RNG_seed)\n",
    "pop = NEAT.Population(genome, params, True, 1.0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a population of 100 simple neural network genomes with randomized weights.  Next step is to define an evaluation function, which will require us to build phenotypes from these genomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(genome):\n",
    "\n",
    "    # this creates a neural network (phenotype) from the genome\n",
    "    net = NEAT.NeuralNetwork()\n",
    "    genome.BuildPhenotype(net)\n",
    "\n",
    "    # let's input just one pattern to the net, activate it once and get the output\n",
    "    net.Input( [ 1.0, 0.0, 1.0 ] )\n",
    "    net.Activate()\n",
    "    output = net.Output() \n",
    "\n",
    "    # the output can be used as any other Python iterable.\n",
    "    # instead of the original decision to select for '0' output on the first output,\n",
    "    # I will select for the output [1,0]\n",
    "    fitness = output[0] + (1 - output[1])\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest fitness in generation 0: 1.3847487012811497\n",
      "Percentage of Max Fitness: 0.6923743506405748\n",
      "Highest fitness in generation 1: 1.6269513980474455\n",
      "Percentage of Max Fitness: 0.8134756990237227\n",
      "Highest fitness in generation 2: 1.7014976657840726\n",
      "Percentage of Max Fitness: 0.8507488328920363\n",
      "Highest fitness in generation 3: 1.7805192458906676\n",
      "Percentage of Max Fitness: 0.8902596229453338\n",
      "Highest fitness in generation 4: 1.8412507847903352\n",
      "Percentage of Max Fitness: 0.9206253923951676\n",
      "Highest fitness in generation 5: 1.8990023622827406\n",
      "Percentage of Max Fitness: 0.9495011811413703\n",
      "Highest fitness in generation 6: 1.9354934634112784\n",
      "Percentage of Max Fitness: 0.9677467317056392\n",
      "Highest fitness in generation 7: 1.9416213769999735\n",
      "Percentage of Max Fitness: 0.9708106884999868\n",
      "Highest fitness in generation 8: 1.959301245633888\n",
      "Percentage of Max Fitness: 0.979650622816944\n",
      "Highest fitness in generation 9: 1.9799004840213486\n",
      "Percentage of Max Fitness: 0.9899502420106743\n"
     ]
    }
   ],
   "source": [
    "for generation in range(10): # run for 10 generations\n",
    "\n",
    "    # retrieve a list of all genomes in the population\n",
    "    genome_list = NEAT.GetGenomeList(pop)\n",
    "\n",
    "    fitness_list = []\n",
    "    # apply the evaluation function to all genomes\n",
    "    for genome in genome_list:\n",
    "        fitness = evaluate(genome)\n",
    "        fitness_list.append(fitness)\n",
    "        genome.SetFitness(fitness)\n",
    "\n",
    "    # Here is where the author recommends to output information on the current generation\n",
    "    top_fit = sorted(fitness_list)[-1]\n",
    "    print(\"Highest fitness in generation \" + str(generation) + \": \" + str(top_fit))\n",
    "    print(\"Percentage of Max Fitness: \" + str(top_fit/2.0))\n",
    "\n",
    "    # advance to the next generation\n",
    "    pop.Epoch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
